{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For Image Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### For DataFrame\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "##### For Query Processing \n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "### For plotting images\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "from IPython.display import display\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from os import listdir\n",
    "from PIL import Image as PImage \n",
    "import os \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagged_data_df = pd.read_pickle(\"tagged_data/tag_data.pkl\")\n",
    "categorical_image_df = pd.read_csv(\"tagged_data/category_wise_image.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_df = pd.read_csv(\"tagged_data/category.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query Processing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_processing(sentence):\n",
    "    # #sentence = input()\n",
    "    # sentence = 'Fetch the images of persons and handbags'\n",
    "    sentence = sentence.lower()\n",
    "    words = nltk.word_tokenize(sentence)\n",
    "\n",
    "    lemmatizer_words = []\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "    for word in words:\n",
    "        lemmatizer_words.append(lemmatizer.lemmatize(word, wordnet.VERB))\n",
    "\n",
    "    ## Stop words Removal\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    refined_words_of_lemmatizer = [word for word in lemmatizer_words if word not in stop_words]\n",
    "    refined_words_of_lemmatizer = ' '.join(refined_words_of_lemmatizer)\n",
    "\n",
    "    ## To remove puntuation marks\n",
    "    final_words_lemmatizer = re.sub(r\"[\\W]\", ' ', refined_words_of_lemmatizer)\n",
    "    final_words_lemmatizer=final_words_lemmatizer.split()\n",
    "    \n",
    "    return final_words_lemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stemmer(final_words_lemmatizer):\n",
    "    stemmer_words= []\n",
    "    stemmer = PorterStemmer()\n",
    "    \n",
    "\n",
    "    for word in final_words_lemmatizer:\n",
    "        if word.endswith('s'):\n",
    "            stemmer_words.append(stemmer.stem(word))\n",
    "        else:\n",
    "            stemmer_words.append(word)\n",
    "            \n",
    "    \n",
    "    return stemmer_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_words_removal(object_list):\n",
    "\n",
    "    words_to_remove = ['image', 'picture',' many', 'fetch', 'get', 'locations', 'location', 'show', 'present', 'many']\n",
    "\n",
    "    object_list = [ i for i in object_list if i not in words_to_remove ]\n",
    "    \n",
    "\n",
    "    return object_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_counter(df, objects_to_detect, if_repeated_objects=False):\n",
    "    \n",
    "    if if_repeated_objects:\n",
    "        objects_list = df.repeated_objects.values\n",
    "        \n",
    "    else:\n",
    "        objects_list = df.objects.values\n",
    "\n",
    "    counter = list()\n",
    "    for objects in objects_list:\n",
    "        c = 0\n",
    "        for i in objects_to_detect:\n",
    "            c += objects.count(i)\n",
    "\n",
    "        counter.append(c)\n",
    "        \n",
    "    return counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_relevance_score(df, not_type=False, how_many=False):\n",
    "    \n",
    "    max_score = max(df.counter)\n",
    "    \n",
    "    counter = df.counter.values\n",
    "    \n",
    "    if how_many: \n",
    "        relevance_score = [i/max_score for i in counter]\n",
    "    \n",
    "    elif not_type:\n",
    "        relevance_score = [1 - (i/number_of_objects) for i in counter]\n",
    "        \n",
    "    else:\n",
    "        relevance_score = [i/number_of_objects for i in counter]\n",
    "    \n",
    "    return relevance_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relevance_score_sorting(df, sentence, how_many= False):\n",
    "    splitted_sentence = sentence.split()\n",
    "\n",
    "    max_score = max(tagged_data_df.counter)\n",
    "    \n",
    "    if how_many:\n",
    "        df['relevance_score'] = generate_relevance_score(df, False, True)\n",
    "        ranked_df = df.sort_values('relevance_score', ascending = False)\n",
    "        \n",
    "        return ranked_df\n",
    "        \n",
    "    \n",
    "    elif 'not' in splitted_sentence:\n",
    "        if len(df[df.counter == 0].index):\n",
    "            df['relevance_score'] = generate_relevance_score(df, True)\n",
    "            ranked_df = df.sort_values('relevance_score', ascending = False)\n",
    "\n",
    "        else:\n",
    "            return False\n",
    "            print('Every image has ', obj[0], 'in it.')\n",
    "    \n",
    "    else:\n",
    "        df['relevance_score'] = generate_relevance_score(df)\n",
    "        ranked_df = df.sort_values('relevance_score', ascending = False)\n",
    "        \n",
    "        return ranked_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "def object_in_db(df):\n",
    "    if df['counter'].any():\n",
    "        return True\n",
    "\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def show_images(PATH):\n",
    "\n",
    "    # This is to get the directory that the program \n",
    "    # is currently running in. \n",
    "    dir_path = os.path.dirname(os.path.realpath(PATH)) \n",
    "    dir_path += \"\\\\val2017\\\\\"\n",
    "\n",
    "    # for root, dirs, files in os.walk(dir_path): \n",
    "    #     for file in files: \n",
    "\n",
    "    for img in img_names:\n",
    "        PATH = dir_path + img\n",
    "\n",
    "        p = PATH\n",
    "        print(p)\n",
    "        image = mpimg.imread(p) # images are color images\n",
    "        plt.gca().clear()\n",
    "        plt.imshow(image);\n",
    "        display.display(plt.gcf())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_class_names(file_name):\n",
    "    \"\"\"Returns a list of class names read from `file_name`.\"\"\"\n",
    "    with open(file_name, 'r') as f:\n",
    "        class_names = f.read().splitlines()\n",
    "    return class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_id_to_detect(img_names, object_list, ranked_df, category_df):\n",
    "    boxes_dicts = list()\n",
    "    class_id_to_detect = list()\n",
    "\n",
    "    for img in img_names:\n",
    "        boxes_dicts.append(ranked_df[ranked_df.image_name == img].repeated_objects_coordinates.values[0][0])\n",
    "\n",
    "\n",
    "    for objects in object_list:\n",
    "        if objects in class_names:\n",
    "            class_id_to_detect.append(category_df[category_df.class_name == objects].index.values[0])\n",
    "\n",
    "    return [class_id_to_detect, boxes_dicts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objects_frequency(obj, ranked_df):\n",
    "\n",
    "    img_names = []\n",
    "    repeated_object_len = []\n",
    "\n",
    "    for i in range(ranked_df.shape[0]):\n",
    "        for objects in obj:\n",
    "            if objects in ranked_df.iloc[i][1]:\n",
    "                if ranked_df.iloc[i][0] not in img_names:\n",
    "                    img_names.append(ranked_df.iloc[i][0])\n",
    "                    repeated_object_len.append(len(ranked_df[ranked_df.image_name == ranked_df.iloc[i][0]].repeated_objects.values[0]))\n",
    "    \n",
    "    return [img_names, repeated_object_len]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def bounding_box(ranked_df, img_names, boxes_dicts, repeated_object_len, class_id_to_detect, class_names, model_size):\n",
    "    \n",
    "#     model_size = ranked_df.iloc[0]['model_size']\n",
    "    \n",
    "\n",
    "    for num, img_name, boxes_dict, objects_len in zip(range(len(img_names)), img_names,\n",
    "                                             boxes_dicts, repeated_object_len):\n",
    "            img = Image.open('val2017/'+img_name)\n",
    "            draw = ImageDraw.Draw(img)\n",
    "            font = ImageFont.truetype(font='files/futur.ttf',\n",
    "                                      size=(img.size[0] + img.size[1]) // 150)\n",
    "            resize_factor = \\\n",
    "                (img.size[0] / model_size[0], img.size[1] / model_size[1])\n",
    "\n",
    "            for cls in class_id_to_detect:\n",
    "                boxes = boxes_dict[cls]\n",
    "                if np.size(boxes) != 0:\n",
    "                    color = np.random.permutation([np.random.randint(256), 255, 0])\n",
    "                    for box in boxes:\n",
    "\n",
    "                        xy, confidence = box[:4], box[4]\n",
    "                        xy = [xy[i] * resize_factor[i % 2] for i in range(4)]\n",
    "                        x0, y0 = xy[0], xy[1]\n",
    "                        thickness = (img.size[0] + img.size[1]) // 200\n",
    "                        for t in np.linspace(0, 1, thickness//4):\n",
    "                            xy[0], xy[1] = xy[0] + t, xy[1] + t\n",
    "                            xy[2], xy[3] = xy[2] - t, xy[3] - t\n",
    "                            draw.rectangle(xy, outline=tuple(color))\n",
    "                        text = '{}'.format(class_names[cls])\n",
    "\n",
    "                        text_size = draw.textsize(text, font=font)\n",
    "                        draw.rectangle([x0, y0 - text_size[1], x0 + text_size[0], y0], fill=tuple(color))\n",
    "                        draw.text((x0, y0 - text_size[1]), text, fill='black', font=font)\n",
    "\n",
    "\n",
    "\n",
    "            display(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_query_type(sentence):\n",
    "    image_retrieval = False\n",
    "    is_there_type = False\n",
    "    location_type = False\n",
    "    splitted_sentence = sentence.split()\n",
    "\n",
    "    if sentence[:2].lower() == 'is' or sentence[:2].lower() == 'if':\n",
    "        return 1\n",
    "    \n",
    "    elif splitted_sentence[0] == 'how' and splitted_sentence[1] == 'many' and (sentence.find('where') > 0 or sentence.find('location') > 0):\n",
    "        return 2\n",
    "        \n",
    "    elif splitted_sentence[0] == 'how' and splitted_sentence[1] == 'many':\n",
    "        return 3\n",
    "    \n",
    "    elif sentence.find('where') > 0 or sentence.find('location') > 0:\n",
    "        return 4\n",
    "\n",
    "    elif sentence.find('images') > 0 or sentence.find('pictures') > 0 or sentence.find('image') > 0 or sentence.find('picture') > 0:\n",
    "        return 5\n",
    "\n",
    "    else:\n",
    "        return False\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def yes_no_type(df, sentence):\n",
    "    \n",
    "    ranked_df = relevance_score_sorting(df, sentence)\n",
    "    \n",
    "    return ranked_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def VQA(sentence, tagged_data_df, class_names, PATH):\n",
    "    print()\n",
    "\n",
    "    model_size = tagged_data_df.iloc[0].model_size\n",
    "\n",
    "    splitted_sentence = sentence.split()\n",
    "\n",
    "    query_result = check_query_type(sentence)\n",
    "\n",
    "\n",
    "    if query_result:\n",
    "\n",
    "        objects_to_detect = stemmer(custom_words_removal(query_processing(sentence)))\n",
    "\n",
    "        number_of_objects = len(objects_to_detect)\n",
    "\n",
    "        tagged_data_df['counter'] = generate_counter(tagged_data_df, objects_to_detect)\n",
    "        \n",
    "        if object_in_db(tagged_data_df):\n",
    "\n",
    "            if query_result == 1:\n",
    "                ranked_df = yes_no_type(tagged_data_df, sentence)\n",
    "\n",
    "                if ranked_df.iloc[0].relevance_score:\n",
    "                    if 'and' in splitted_sentence and ranked_df.iloc[0].relevance_score == 1:\n",
    "                        print(\"Yes in the following image:\")\n",
    "                        print(ranked_df.iloc[0]['image_name'][:1])\n",
    "\n",
    "                    elif 'not' in splitted_sentence and ranked_df.iloc[0].relevance_score == 1:\n",
    "                        print(\"Yes in the following image:\")\n",
    "                        for img_name in ranked_df[ranked_df.relevance_score != 0]['image_name'].values:\n",
    "                            print(img_name)\n",
    "\n",
    "                    else:\n",
    "                        if ranked_df.iloc[0].relevance_score:\n",
    "                            print('Sorry, there is no image with all the objects present in it. Only images with either of the objects present in it:')\n",
    "                            print()\n",
    "                            for img_name in ranked_df[ranked_df.relevance_score != 0]['image_name'].values:\n",
    "                                print(img_name)\n",
    "\n",
    "                else:  \n",
    "                    print(\"No image could be found.\")\n",
    "\n",
    "            if query_result == 2:\n",
    "                tagged_data_df['counter'] = generate_counter(tagged_data_df, objects_to_detect, True)\n",
    "                ranked_df = relevance_score_sorting(tagged_data_df, sentence, True)\n",
    "\n",
    "                if ranked_df.iloc[0].relevance_score:\n",
    "                    if 'or' in splitted_sentence and 'and' in splitted_sentence:\n",
    "                        if splitted_sentence.index('or') < splitted_sentence.index('and'):\n",
    "                            fetched_df = ranked_df[ranked_df.relevance_score!=0]\n",
    "                            print(\"%s\\t\\t\\t%s\" %(\"Image Name\", \"Total count\"))\n",
    "                            for img, i in zip(fetched_df['image_name'].values,  fetched_df.counter.values):\n",
    "                                print(\"%s\\t\\t\\t%d\" %(img, i))\n",
    "\n",
    "                            image_names, repeated_object_len = objects_frequency(objects_to_detect, ranked_df[ranked_df.relevance_score == 1])\n",
    "                            class_ids, boxes_dict= class_id_to_detect(image_names, objects_to_detect, ranked_df[ranked_df.relevance_score == 1], category_df)\n",
    "                            bounding_box(ranked_df[ranked_df.relevance_score == 1], image_names, boxes_dict, repeated_object_len, class_ids, class_names, model_size)\n",
    "                            quit()\n",
    "\n",
    "                    if 'and' in splitted_sentence and ranked_df.iloc[0].relevance_score == 1:\n",
    "                        fetched_df = ranked_df[ranked_df.relevance_score==1]\n",
    "                        print(\"%s\\t\\t\\t%s\" %(\"Image Name\", \"Total count\"))\n",
    "                        for img, i in zip(fetched_df['image_name'].values,  fetched_df.counter.values):\n",
    "                            print(\"%s\\t\\t\\t%d\" %(img, i))\n",
    "                        image_names, repeated_object_len = objects_frequency(objects_to_detect, ranked_df[ranked_df.relevance_score == 1])\n",
    "                        class_ids, boxes_dict= class_id_to_detect(image_names, objects_to_detect, ranked_df[ranked_df.relevance_score == 1], category_df)\n",
    "                        bounding_box(ranked_df[ranked_df.relevance_score == 1], image_names, boxes_dict, repeated_object_len, class_ids, class_names, model_size)\n",
    "\n",
    "\n",
    "\n",
    "                    elif 'and' in splitted_sentence and ranked_df.iloc[0].relevance_score != 1:\n",
    "                        print('Sorry, there is no image with all the objects present in it. Only images with either of the objects present in it:')\n",
    "                        print()\n",
    "                        for img_name in ranked_df[ranked_df.relevance_score != 0]['image_name'].values:\n",
    "                            print(img_name)\n",
    "\n",
    "                        image_names, repeated_object_len = objects_frequency(objects_to_detect, ranked_df[ranked_df.relevance_score == 1])\n",
    "                        class_ids, boxes_dict= class_id_to_detect(image_names, objects_to_detect, ranked_df[ranked_df.relevance_score == 1], category_df)\n",
    "                        bounding_box(ranked_df[ranked_df.relevance_score == 1], image_names, boxes_dict, repeated_object_len, class_ids, class_names, model_size)\n",
    "\n",
    "\n",
    "                    else:\n",
    "                        fetched_df = ranked_df[ranked_df.relevance_score==1]\n",
    "                        print(\"%s\\t\\t\\t%s\" %(\"Image Name\", \"Total count\"))\n",
    "                        for img, i in zip(fetched_df['image_name'].values,  fetched_df.counter.values):\n",
    "                            print(\"%s\\t\\t\\t%d\" %(img, i))\n",
    "\n",
    "                        image_names, repeated_object_len = objects_frequency(objects_to_detect, ranked_df[ranked_df.relevance_score == 1])\n",
    "                        class_ids, boxes_dict= class_id_to_detect(image_names, objects_to_detect, ranked_df[ranked_df.relevance_score == 1], category_df)\n",
    "                        bounding_box(ranked_df[ranked_df.relevance_score != 0], image_names, boxes_dict, repeated_object_len, class_ids, class_names, model_size)\n",
    "\n",
    "\n",
    "                else:  \n",
    "                    print(\"No image could be found.\")\n",
    "\n",
    "            if query_result == 3:\n",
    "                tagged_data_df['counter'] = generate_counter(tagged_data_df, objects_to_detect, True)\n",
    "                ranked_df = relevance_score_sorting(tagged_data_df, sentence, True)\n",
    "\n",
    "                if ranked_df.iloc[0].relevance_score:\n",
    "                    if 'and' in splitted_sentence and ranked_df.iloc[0].relevance_score == 1:\n",
    "                        fetched_df = ranked_df[ranked_df.relevance_score==1]\n",
    "                        print(\"%s\\t\\t\\t%s\" %(\"Image Name\", \"Total count\"))\n",
    "                        for img, i in zip(fetched_df['image_name'].values,  fetched_df.counter.values):\n",
    "                            print(\"%s\\t\\t\\t%d\" %(img, i))\n",
    "\n",
    "\n",
    "                    elif 'and' in splitted_sentence and ranked_df.iloc[0].relevance_score != 1:\n",
    "                        print('Sorry, there is no image with all the objects present in it. Only images with either of the objects present in it:')\n",
    "                        print()\n",
    "                        for img_name in ranked_df[ranked_df.relevance_score != 0]['image_name'].values:\n",
    "                            print(img_name)\n",
    "\n",
    "                    else:\n",
    "                       fetched_df = ranked_df[ranked_df.relevance_score==1]\n",
    "                        print(\"%s\\t\\t\\t%s\" %(\"Image Name\", \"Total count\"))\n",
    "                        for img, i in zip(fetched_df['image_name'].values,  fetched_df.counter.values):\n",
    "                            print(\"%s\\t\\t\\t%d\" %(img, i))\n",
    "                else:  \n",
    "                    print(\"No image could be found.\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            if query_result == 4:\n",
    "                ranked_df = relevance_score_sorting(tagged_data_df, sentence)\n",
    "\n",
    "                if ranked_df.iloc[0].relevance_score:\n",
    "                    if 'or' in splitted_sentence and 'and' in splitted_sentence:\n",
    "                        if splitted_sentence.index('or') < splitted_sentence.index('and'):\n",
    "                            print(\"Yes in the following image:\")\n",
    "                            for img_name in ranked_df[ranked_df.relevance_score != 0]['image_name'].values:\n",
    "                                print(img_name)\n",
    "\n",
    "                            image_names, repeated_object_len = objects_frequency(objects_to_detect, ranked_df[ranked_df.relevance_score == 1])\n",
    "                            class_ids, boxes_dict= class_id_to_detect(image_names, objects_to_detect, ranked_df[ranked_df.relevance_score == 1], category_df)\n",
    "                            bounding_box(ranked_df[ranked_df.relevance_score != 0], image_names, boxes_dict, repeated_object_len, class_ids, class_names, model_size)\n",
    "                            quit()\n",
    "\n",
    "                    if 'and' in splitted_sentence and ranked_df.iloc[0].relevance_score == 1:\n",
    "                        print(\"Yes in the following image:\")\n",
    "                        image_names, repeated_object_len = objects_frequency(objects_to_detect, ranked_df[ranked_df.relevance_score == 1])\n",
    "                        class_ids, boxes_dict= class_id_to_detect(image_names, objects_to_detect, ranked_df[ranked_df.relevance_score == 1], category_df)\n",
    "                        bounding_box(ranked_df[ranked_df.relevance_score == 1], image_names, boxes_dict, repeated_object_len, class_ids, class_names, model_size)\n",
    "\n",
    "                    elif 'and' in splitted_sentence and ranked_df.iloc[0].relevance_score != 1:\n",
    "                        print('Sorry, there is no image with all the objects present in it. Only images with either of the objects present in it:')\n",
    "                        image_names, repeated_object_len = objects_frequency(objects_to_detect, ranked_df[ranked_df.relevance_score >0])\n",
    "                        class_ids, boxes_dict= class_id_to_detect(image_names, objects_to_detect, ranked_df[ranked_df.relevance_score >0], category_df)\n",
    "                        bounding_box(ranked_df[ranked_df.relevance_score > 0], image_names, boxes_dict, repeated_object_len, class_ids, class_names, model_size)\n",
    "\n",
    "                    else:\n",
    "                        print(\"Yes in the following image:\")\n",
    "                        image_names, repeated_object_len = objects_frequency(objects_to_detect, ranked_df[ranked_df.relevance_score == 1])\n",
    "                        class_ids, boxes_dict= class_id_to_detect(image_names, objects_to_detect, ranked_df[ranked_df.relevance_score == 1], category_df)\n",
    "                        bounding_box(ranked_df[ranked_df.relevance_score != 0], image_names, boxes_dict, repeated_object_len, class_ids, class_names, model_size)\n",
    "\n",
    "                else:  \n",
    "                    print(\"No image could be found.\")\n",
    "\n",
    "\n",
    "            if query_result == 5:\n",
    "                ranked_df = relevance_score_sorting(tagged_data_df, sentence)\n",
    "\n",
    "                if 'not' in splitted_sentence and ranked_df.iloc[0].relevance_score == 1:\n",
    "                        print(\"Following are the relevant images:\")\n",
    "                        for img_name in ranked_df[ranked_df.relevance_score != 0]['image_name'].values:\n",
    "                            print(img_name)\n",
    "\n",
    "                elif ranked_df.iloc[0].relevance_score:\n",
    "                    if 'and' in splitted_sentence and ranked_df.iloc[0].relevance_score == 1:\n",
    "                        print(\"Following are the relevant images:\")\n",
    "                        for img in ranked_df[ranked_df.relevance_score==1]['image_name'].values:\n",
    "                            print(img)\n",
    "\n",
    "\n",
    "                    elif 'and' in splitted_sentence and ranked_df.iloc[0].relevance_score != 1:\n",
    "                        print('Sorry, there is no image with all the objects present in it. Only images with either of the objects present in it:')\n",
    "                        print()\n",
    "                        for img_name in ranked_df[ranked_df.relevance_score != 0]['image_name'].values:\n",
    "\n",
    "                            print(img_name)\n",
    "\n",
    "                    else:\n",
    "                        print(\"Following are the relevant images:\")\n",
    "                        for img_name in ranked_df[ranked_df.relevance_score != 0]['image_name'].values:\n",
    "                            print(img_name)\n",
    "\n",
    "                else: \n",
    "                    print(\"No image could be found.\")\n",
    "        \n",
    "        else:\n",
    "            print(\"'\",obj[0],\"'\",\"can't be found anywhere in the database.\")\n",
    "        \n",
    "        \n",
    "    else:\n",
    "        print('Sorry!! The query could not be processed. RETRY!!!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter your query: Fetch images of persons and cars.\n",
      "\n",
      "Yes in the following image:\n",
      "city.jpg\n",
      "bike3.jpg\n",
      "bike2.jpg\n"
     ]
    }
   ],
   "source": [
    "PATH = 'val2017'\n",
    "\n",
    "class_names = load_class_names('files/coco.names')\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    sentence = input(\"Enter your query: \")\n",
    "    VQA(sentence, tagged_data_df, class_names, PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "\n",
    "labelencoder_class_name = LabelEncoder()\n",
    "labelencoder_category_name = LabelEncoder()\n",
    "\n",
    "category_df2.class_name = labelencoder_class_name.fit_transform(category_df2.class_name)\n",
    "category_df2.category_name = labelencoder_category_name.fit_transform(category_df2.category_name)\n",
    "X = np.array(category_df2.class_name).reshape(-1, 1)\n",
    "\n",
    "test = pd.DataFrame({'class_name': category_df.class_name, 'class_name_vector': category_df2.class_name, 'category_name': category_df.category_name, 'category_name_vector': category_df2.category_name})\n",
    "category_df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'DecisionTreeClassifier' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-9f6462b70395>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mclf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDecisionTreeClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcategory_df2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcategory_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'DecisionTreeClassifier' is not defined"
     ]
    }
   ],
   "source": [
    "clf = DecisionTreeClassifier(random_state=0)\n",
    "clf.fit(X, category_df2.category_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[48],\n",
       "       [ 9],\n",
       "       [18],\n",
       "       [43],\n",
       "       [ 0],\n",
       "       [16],\n",
       "       [73],\n",
       "       [74],\n",
       "       [11],\n",
       "       [72]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = np.array(category_df2.class_name[:10]).reshape(-1, 1)\n",
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6, 8, 8, 8, 8, 8, 8, 8, 8, 8])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['person' 'transport' 'transport' 'transport' 'transport' 'transport'\n",
      " 'transport' 'transport' 'transport' 'transport']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(labelencoder_category_name.inverse_transform(pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-57-c480125a9d55>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'y_test' is not defined"
     ]
    }
   ],
   "source": [
    "for i in range(len(pred)):\n",
    "    print(pred[i], y_test[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageDraw, ImageFont\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
